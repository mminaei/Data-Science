{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('NIOBRARA_Clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tm_depth       44651.0\n",
       "lat            44651.0\n",
       "long           44651.0\n",
       "ground_elev    44651.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stat = test_data.describe()\n",
    "data_stat.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_features = ['tm_depth', 'lat', 'long', 'ground_elev']\n",
    "selected_data = test_data[selected_features]\n",
    "selected_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMS Error: 1260.85855642\n",
      "Random Forest Regression RMS Error: 688.440476125\n",
      "XGBoost Regression RMS Error: 691.999372717\n"
     ]
    }
   ],
   "source": [
    "selected_features_for_ML = ['lat', 'long', 'ground_elev']\n",
    "\n",
    "\n",
    "# Separating Features/Input (X) and Target/Output (y)\n",
    "\n",
    "X = selected_data[selected_features_for_ML]\n",
    "y = selected_data['tm_depth']\n",
    "\n",
    "# Split data into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# Linear Regression Model\n",
    "# ------------------------------------\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Instantiate model\n",
    "linreg = LinearRegression()\n",
    "# Fit Model\n",
    "linreg.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = linreg.predict(X_test)\n",
    "# Calculate RMS Error\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Linear Regression RMS Error:', RMSE)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# Random Forest Model\n",
    "# ------------------------------------\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model\n",
    "rfreg = RandomForestRegressor(n_estimators=500, random_state=1)\n",
    "# Fit Model\n",
    "rfreg.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = rfreg.predict(X_test)\n",
    "# Calculate RMS Error\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('Random Forest Regression RMS Error:', RMSE)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# XGBoost Regresoor Model\n",
    "# ------------------------------------\n",
    "import xgboost as xgb\n",
    "# Instantiate model\n",
    "xgb = xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.1)\n",
    "# Fit Model\n",
    "xgb.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = xgb.predict(X_test)\n",
    "# Calculate RMS Error\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('XGBoost Regression RMS Error:', RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Run (Predicting NIOBRARA by the help of PIERRE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohse\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "test_data2 = pd.read_csv('NIOBRARA_Clean.csv')\n",
    "test_data3 = pd.read_csv('PIERRE_Clean.csv')\n",
    "\n",
    "#Read PIERRE columns\n",
    "selected_features = ['tm_depth', 'lat', 'long', 'ground_elev']\n",
    "selected_data = test_data3[selected_features]\n",
    "selected_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting PIERRE\n",
      "Linear Regression RMS Error: 1033.24093677\n",
      "Random Forest Regression RMS Error: 691.969752241\n",
      "XGBoost Regression RMS Error: 723.649743054\n",
      "Predicting NIOBRARA with the help of PIERRE-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohse\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3033: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-131e6c593c46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[0mlinreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m# Fit Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m \u001b[0mlinreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;31m# Predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 482\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    460\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[1;32m--> 462\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "#First predict PIERRE\n",
    "print('Predicting PIERRE')\n",
    "selected_features_for_ML = ['lat', 'long', 'ground_elev']\n",
    "\n",
    "\n",
    "# Separating Features/Input (X) and Target/Output (y)\n",
    "\n",
    "X = selected_data[selected_features_for_ML]\n",
    "y = selected_data['tm_depth']\n",
    "\n",
    "# Split data into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# Linear Regression Model\n",
    "# ------------------------------------\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Instantiate model\n",
    "linreg = LinearRegression()\n",
    "# Fit Model\n",
    "linreg.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred1 = linreg.predict(X_test)\n",
    "# Calculate RMS Error\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred1))\n",
    "print('Linear Regression RMS Error:', RMSE)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# Random Forest Model\n",
    "# ------------------------------------\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model\n",
    "rfreg = RandomForestRegressor(n_estimators=500, random_state=1)\n",
    "# Fit Model\n",
    "rfreg.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred2 = rfreg.predict(X_test)\n",
    "# Calculate RMS Error\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred2))\n",
    "\n",
    "print('Random Forest Regression RMS Error:', RMSE)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# XGBoost Regresoor Model\n",
    "# ------------------------------------\n",
    "import xgboost as xgb\n",
    "# Instantiate model\n",
    "xgb = xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.1)\n",
    "# Fit Model\n",
    "xgb.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred3 = xgb.predict(X_test)\n",
    "# Calculate RMS Error\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred3))\n",
    "\n",
    "print('XGBoost Regression RMS Error:', RMSE)\n",
    "print('Predicting NIOBRARA with the help of PIERRE-------------------------')\n",
    "\n",
    "\n",
    "selected_features = ['tm_depth', 'lat', 'long', 'ground_elev']\n",
    "selected_data = test_data2[selected_features]+test_data3['tm_depth']\n",
    "selected_data.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Separating Features/Input (X) and Target/Output (y)\n",
    "\n",
    "X = selected_data[selected_features_for_ML]\n",
    "y = selected_data['tm_depth']\n",
    "\n",
    "# Split data into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# Linear Regression Model\n",
    "# ------------------------------------\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Instantiate model\n",
    "linreg = LinearRegression()\n",
    "# Fit Model\n",
    "linreg.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = linreg.predict(X_test)\n",
    "# Calculate RMS Error\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Linear Regression RMS Error:', RMSE)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# Random Forest Model\n",
    "# ------------------------------------\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model\n",
    "rfreg = RandomForestRegressor(n_estimators=500, random_state=1)\n",
    "# Fit Model\n",
    "rfreg.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = rfreg.predict(X_test)\n",
    "# Calculate RMS Error\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('Random Forest Regression RMS Error:', RMSE)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# XGBoost Regresoor Model\n",
    "# ------------------------------------\n",
    "import xgboost as xgb\n",
    "# Instantiate model\n",
    "xgb = xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.1)\n",
    "# Fit Model\n",
    "xgb.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = xgb.predict(X_test)\n",
    "# Calculate RMS Error\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('XGBoost Regression RMS Error:', RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
